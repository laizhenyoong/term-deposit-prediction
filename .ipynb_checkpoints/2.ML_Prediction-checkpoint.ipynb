{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdcc01f-0f6c-47d9-91fe-2996206cfc29",
   "metadata": {},
   "source": [
    "# **Term Deposit Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f39f1-1545-4442-a860-8c56899b0afb",
   "metadata": {},
   "source": [
    "## Machine Learning Predicition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f933f-4281-4030-b5dd-55101be61b22",
   "metadata": {},
   "source": [
    "In this assignment, we will predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e1190-e731-4600-a96d-200b6ed0a627",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce386919-9d3e-4f2c-a902-d218ad813a24",
   "metadata": {},
   "source": [
    "Perform exploratory Data Analysis and determine Training Labels\n",
    "\n",
    "- Standardize the data\n",
    "- Split into training data and test data\n",
    "- Find best Hyperparameter for SVM, Classification Trees and Logistic Regression\n",
    "- Find the method performs best using test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627dcae-27bf-4788-b975-c71667df3a6b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7311541-f4f0-4415-9801-cebdd4b90f3c",
   "metadata": {},
   "source": [
    "## Import Libraries and Define Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06bfed89-8ffe-4e4a-8911-41db175a535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54708868-4e4d-47f7-9e28-ff631d1c6eb4",
   "metadata": {},
   "source": [
    "## Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e4ee18-30aa-4ca6-98ec-bc9816bdbb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_others</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
       "0         0.0              0.0               0.0            0.0   \n",
       "1         0.0              0.0               0.0            0.0   \n",
       "2         0.0              0.0               1.0            0.0   \n",
       "3         0.0              1.0               0.0            0.0   \n",
       "4         0.0              0.0               0.0            0.0   \n",
       "\n",
       "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
       "0             1.0          0.0                0.0           0.0          0.0   \n",
       "1             0.0          0.0                0.0           0.0          0.0   \n",
       "2             0.0          0.0                0.0           0.0          0.0   \n",
       "3             0.0          0.0                0.0           0.0          0.0   \n",
       "4             0.0          0.0                0.0           0.0          0.0   \n",
       "\n",
       "   job_technician  ...  month_jun  month_mar  month_may  month_nov  month_oct  \\\n",
       "0             0.0  ...        0.0        0.0        1.0        0.0        0.0   \n",
       "1             1.0  ...        0.0        0.0        1.0        0.0        0.0   \n",
       "2             0.0  ...        0.0        0.0        1.0        0.0        0.0   \n",
       "3             0.0  ...        0.0        0.0        1.0        0.0        0.0   \n",
       "4             0.0  ...        0.0        0.0        1.0        0.0        0.0   \n",
       "\n",
       "   month_sep  poutcome_failure  poutcome_other  poutcome_others  \\\n",
       "0        0.0               0.0             0.0              1.0   \n",
       "1        0.0               0.0             0.0              1.0   \n",
       "2        0.0               0.0             0.0              1.0   \n",
       "3        0.0               0.0             0.0              1.0   \n",
       "4        0.0               0.0             0.0              1.0   \n",
       "\n",
       "   poutcome_success  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the 'bank-full2.csv' file using pandas read_csv function\n",
    "X = pd.read_csv(\"bank-full2.csv\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1831b854-96e2-44e0-8a71-2575120e940c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'education_primary', 'education_secondary', 'education_tertiary',\n",
       "       'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
       "       'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
       "       'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
       "       'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'poutcome_failure', 'poutcome_other', 'poutcome_others',\n",
       "       'poutcome_success'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378cacae-3c2a-4c62-86ad-1f17300bea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14192\\2180486564.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['y'] = y['y'].map({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the 'bank-full.csv' file using pandas read_csv function\n",
    "data = pd.read_csv(\"bank-full.csv\", sep=';')\n",
    "\n",
    "# Extract the 'y' column (target variable) as a separate DataFrame 'y'\n",
    "y = data[['y']]\n",
    "\n",
    "# Convert 'yes' and 'no' to 1 and 0 in the 'y' column\n",
    "y['y'] = y['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Convert 'y' DataFrame to a numpy array\n",
    "y_numpy = y['y'].values\n",
    "\n",
    "# Print the resulting numpy array\n",
    "print(y_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e118fa8-bd3b-4915-a613-a368053d44c2",
   "metadata": {},
   "source": [
    "Standardize the data in X then reassign it to the variable X using the transform provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af0161a-ee80-4e70-ab93-0f814ef647e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.35936869 -0.52373954 -0.1844147  ... -0.20597248  0.47251925\n",
      "  -0.185948  ]\n",
      " [-0.35936869 -0.52373954 -0.1844147  ... -0.20597248  0.47251925\n",
      "  -0.185948  ]\n",
      " [-0.35936869 -0.52373954  5.42256115 ... -0.20597248  0.47251925\n",
      "  -0.185948  ]\n",
      " ...\n",
      " [-0.35936869 -0.52373954 -0.1844147  ... -0.20597248 -2.11631591\n",
      "   5.37784754]\n",
      " [-0.35936869  1.909346   -0.1844147  ... -0.20597248  0.47251925\n",
      "  -0.185948  ]\n",
      " [-0.35936869 -0.52373954  5.42256115 ...  4.85501757 -2.11631591\n",
      "  -0.185948  ]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a StandardScaler object for feature scaling\n",
    "transform = preprocessing.StandardScaler()\n",
    "\n",
    "# Apply the StandardScaler to the features in the DataFrame 'X'\n",
    "# This step scales the features to have zero mean and unit variance\n",
    "X = transform.fit_transform(X)\n",
    "\n",
    "# Display the resulting scaled features in the DataFrame 'X'\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec615e92-6ab8-4b30-9ca8-7e8e2ce6e2c5",
   "metadata": {},
   "source": [
    "Use the function train_test_split to split the data X and Y into training and test data. Set the parameter test_size to 0.3 and random_state to 7. The training data and test data should be assigned to the following labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b6688-474e-48f3-880a-0709b543d4dc",
   "metadata": {},
   "source": [
    "<code>X_train, X_test, Y_train, Y_test</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085a80a2-26a4-4746-a593-3079d5d7e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train data (31647, 44)\n",
      "y train data (31647, 1)\n",
      "x test data  (13564, 44)\n",
      "y test data  (13564, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=7)\n",
    "print('x train data {}'.format(X_train.shape))\n",
    "print('y train data {}'.format(y_train.shape))\n",
    "print('x test data  {}'.format(X_test.shape))\n",
    "print('y test data  {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4175ad0-3aff-4cee-86f6-e61e3a182307",
   "metadata": {},
   "source": [
    "## Comparing base models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a73e4c-0e9f-418c-99d2-dd96509b9c60",
   "metadata": {},
   "source": [
    "Explore the performance of fundamental classification algorithmsâ€”'Logistic Regression', 'K-Nearest Neighbors', 'Decision Tree', 'Gaussian Naive Bayes', and 'Support Vector Machine (SVM)' using metrics such as 'Accuracy', 'Precision', 'Recall', 'F1 Score', and confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6a7ae6-4189-4de0-94b7-a36e9239fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KFold object with 10 folds for cross-validation\n",
    "kfold = model_selection.KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f8923-a393-4167-9327-3b69b81c44de",
   "metadata": {},
   "source": [
    "We utilize k-fold cross-validation to ensure robust and unbiased model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a813c9-37e3-4c8e-b1b2-0cd69475eaaf",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d16fe8-f027-4646-a315-72a118eadabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "LogReg = LogisticRegression(solver='lbfgs')\n",
    "LogReg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predictions on the test set\n",
    "LogReg_y_pred = LogReg.predict(X_test)\n",
    "LogReg_Score = LogReg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76507f0-8266-4d22-b5b6-f79ab508fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     12030\n",
      "           1       0.59      0.18      0.27      1534\n",
      "\n",
      "    accuracy                           0.89     13564\n",
      "   macro avg       0.75      0.58      0.61     13564\n",
      "weighted avg       0.87      0.89      0.87     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "LogReg_ScoreAccuracy = accuracy_score(y_test, LogReg_y_pred)\n",
    "LogReg_PrecisionScore = precision_score(y_test, LogReg_y_pred)\n",
    "LogReg_RecallScore = recall_score(y_test, LogReg_y_pred)\n",
    "LogReg_F1 = f1_score(y_test, LogReg_y_pred)\n",
    "\n",
    "# Cross-validation results\n",
    "cross_validation_result = model_selection.cross_val_score(LogReg, X_train, y_train.values.ravel(), cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "base_model_results = pd.DataFrame(\n",
    "    [['Logistic Regression', LogReg_ScoreAccuracy, LogReg_PrecisionScore,\n",
    "      LogReg_RecallScore, LogReg_F1, cross_validation_result.mean(), cross_validation_result.std()]],\n",
    "    columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Mean', 'Std Deviation']\n",
    ")\n",
    "\n",
    "# Display classification report\n",
    "print('\\nLogistic Regression Classification Report:\\n', metrics.classification_report(y_test, LogReg_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6933fc-a4ee-4bbd-b86d-8a485b94a560",
   "metadata": {},
   "source": [
    "### 2. K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff50db91-c6b2-4488-92dc-43180b26f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors model\n",
    "Knn = KNeighborsClassifier(n_neighbors=9, weights='uniform', metric='euclidean')\n",
    "Knn.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predictions on the test set\n",
    "Knn_y_pred = Knn.predict(X_test)\n",
    "Knn_Score = Knn.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "527b683c-0c83-48a2-b00b-978a9da0d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors (K-NN) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     12030\n",
      "           1       0.52      0.23      0.32      1534\n",
      "\n",
      "    accuracy                           0.89     13564\n",
      "   macro avg       0.72      0.60      0.63     13564\n",
      "weighted avg       0.86      0.89      0.87     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "Knn_ScoreAccuracy = accuracy_score(y_test, Knn_y_pred)\n",
    "Knn_PrecisionScore = precision_score(y_test, Knn_y_pred)\n",
    "Knn_RecallScore = recall_score(y_test, Knn_y_pred)\n",
    "Knn_F1 = f1_score(y_test, Knn_y_pred)\n",
    "\n",
    "# Cross-validation results\n",
    "cross_validation_result = model_selection.cross_val_score(Knn, X_train, y_train.values.ravel(), cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Create a DataFrame for the results and append it to the existing base_model_results\n",
    "knn_models_results = pd.DataFrame(\n",
    "    [['K-Nearest Neighbors', Knn_ScoreAccuracy, Knn_PrecisionScore,\n",
    "      Knn_RecallScore, Knn_F1, cross_validation_result.mean(), cross_validation_result.std()]],\n",
    "    columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Mean', 'Std Deviation']\n",
    ")\n",
    "\n",
    "base_model_results = pd.concat([base_model_results, knn_models_results], ignore_index=True)\n",
    "\n",
    "# Display classification report\n",
    "print('\\nK-Nearest Neighbors (K-NN) Classification Report:\\n', metrics.classification_report(y_test, Knn_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5b81e-5b5b-473f-aba3-636af1a8015c",
   "metadata": {},
   "source": [
    "### 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c2bce-f090-41b4-8b2a-464c18be0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM) model with Radial Basis Function (RBF) kernel\n",
    "Svm = SVC(random_state=0, kernel='rbf', probability=True)\n",
    "Svm.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predictions on the test set\n",
    "Svm_y_pred = Svm.predict(X_test)\n",
    "Svm_Score = Svm.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3d702-d8ea-4888-aaf7-bdbd7182b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation metrics\n",
    "Svm_ScoreAccuracy = accuracy_score(y_test, Svm_y_pred)\n",
    "Svm_PrecisionScore = precision_score(y_test, Svm_y_pred)\n",
    "Svm_RecallScore = recall_score(y_test, Svm_y_pred)\n",
    "Svm_F1 = f1_score(y_test, Svm_y_pred)\n",
    "\n",
    "# Cross-validation results\n",
    "cross_validation_result = model_selection.cross_val_score(Svm, X_train, y_train.values.ravel(), cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Create a DataFrame for the results and append it to the existing base_model_results\n",
    "svm_models_results = pd.DataFrame(\n",
    "    [['SVM (RBF)', Svm_ScoreAccuracy, Svm_PrecisionScore,\n",
    "      Svm_RecallScore, Svm_F1, cross_validation_result.mean(), cross_validation_result.std()]],\n",
    "    columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Mean', 'Std Deviation']\n",
    ")\n",
    "base_model_results = pd.concat([base_model_results, svm_models_results], ignore_index=True)\n",
    "\n",
    "# Display classification report\n",
    "print('\\nSVM (RBF) Classification Report:\\n', metrics.classification_report(y_test, Svm_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473f04a-87e5-4830-913d-4edd2d319fc3",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1cf23ba-f12c-49ca-b4c0-d6b05fa677a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes (GNB) model\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predictions on the test set\n",
    "GNB_y_pred = GNB.predict(X_test)\n",
    "GNB_Score = GNB.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c51c020-4028-43d5-a006-36a569db5379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussian Naive Bayes (GNB) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     12030\n",
      "           1       0.36      0.42      0.39      1534\n",
      "\n",
      "    accuracy                           0.85     13564\n",
      "   macro avg       0.64      0.66      0.65     13564\n",
      "weighted avg       0.86      0.85      0.86     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "GNB_ScoreAccuracy = accuracy_score(y_test, GNB_y_pred)\n",
    "GNB_PrecisionScore = precision_score(y_test, GNB_y_pred)\n",
    "GNB_RecallScore = recall_score(y_test, GNB_y_pred)\n",
    "GNB_F1 = f1_score(y_test, GNB_y_pred)\n",
    "\n",
    "# Cross-validation results\n",
    "cross_validation_result = model_selection.cross_val_score(GNB, X_train, y_train.values.ravel(), cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Create a DataFrame for the results and append it to the existing base_model_results\n",
    "GNB_models_results = pd.DataFrame(\n",
    "    [['Naive Bayes (Gaussian)', GNB_ScoreAccuracy, GNB_PrecisionScore,\n",
    "      GNB_RecallScore, GNB_F1, cross_validation_result.mean(), cross_validation_result.std()]],\n",
    "    columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Mean', 'Std Deviation']\n",
    ")\n",
    "base_model_results = pd.concat([base_model_results, GNB_models_results], ignore_index=True)\n",
    "\n",
    "# Display classification report\n",
    "print('\\nGaussian Naive Bayes (GNB) Classification Report:\\n', metrics.classification_report(y_test, GNB_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba3b75-3599-4002-b102-47b83674f942",
   "metadata": {},
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13a48194-cfed-4066-97c7-1510383cefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree model\n",
    "dTree = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "dTree.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "dTree_y_pred = dTree.predict(X_test)\n",
    "dTree_Score = dTree.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08526198-1239-490f-befd-e4bb225dd7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9217303377887319\n",
      "Test set score: 0.8829253907401946\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     12030\n",
      "           1       0.46      0.22      0.29      1534\n",
      "\n",
      "    accuracy                           0.88     13564\n",
      "   macro avg       0.68      0.59      0.61     13564\n",
      "weighted avg       0.86      0.88      0.86     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "dTree_ScoreAccuracy = accuracy_score(y_test, dTree_y_pred)\n",
    "dTree_PrecisionScore = precision_score(y_test, dTree_y_pred)\n",
    "dTree_RecallScore = recall_score(y_test, dTree_y_pred)\n",
    "dTree_F1 = f1_score(y_test, dTree_y_pred)\n",
    "\n",
    "# Cross-validation results\n",
    "cross_validation_result = model_selection.cross_val_score(dTree, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Create a DataFrame for the results and append it to the existing base_model_results\n",
    "dTree_models_results = pd.DataFrame(\n",
    "    [['Decision Tree', dTree_ScoreAccuracy, dTree_PrecisionScore,\n",
    "      dTree_RecallScore, dTree_F1, cross_validation_result.mean(), cross_validation_result.std()]],\n",
    "    columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Mean', 'Std Deviation']\n",
    ")\n",
    "base_model_results = pd.concat([base_model_results, dTree_models_results], ignore_index=True)\n",
    "\n",
    "# Display classification report\n",
    "print('\\nDecision Tree Classification Report:\\n', metrics.classification_report(y_test, dTree_y_pred))\n",
    "print(f'Training set score: {dTree.score(X_train, y_train)}')\n",
    "print(f'Test set score: {dTree.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ac34c-2f8c-45c1-8be7-619af4a76128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a890e0-4260-4f10-8e30-51f05f881a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
